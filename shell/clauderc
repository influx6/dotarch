#!/bin/bash

LITELLM_MASTER_KEY=litellm-647e8dd5-7197-4639-899f-463408b3fb44
LITELLM_SALT_KEY=litellm-3efab3d2-e033-46fe-976f-f2f05115ef98
ENABLE_NETWORK_MONITOR=true
LOG_LEVEL=DEBUG

# if has_command "claude"; then
#     curl -fsSL https://claude.ai/install.sh | bash
# fi

litellm_start(){
    if has_command "pip"; then
        if no_command "litellm"; then
            echo "Installing litellm"
            pip install 'litellm[proxy]'
        fi
    else
        echo "Unable to install litellm with pip, please setup"
    fi

    if no_command "litellm"; then
        echo "No litellm for me to run with"
    else
        litellm --config $DOTFILES/config/litellm/copilot-config.yaml
    fi
}

claude_start() {
    export ANTHROPIC_AUTH_TOKEN=$LITELLM_MASTER_KEY
    export ANTHROPIC_BASE_URL="http://localhost:4000"
    export ANTHROPIC_MODEL="claude-opus-4.5"
    export ANTHROPIC_SMALL_FAST_MODEL="gpt-4"
    export CLAUDE_CODE_MAX_OUTPUT_TOKENS = 64000
    if no_command "claude"; then
        if has_command "npm"; then
            npm install -g @anthropic-ai/claude-code
        else
            echo "Unable to install claude via npm, please setup"
        fi
    else
        claude
    fi
}

test_gemini_flash() {
    curl --location 'http://0.0.0.0:4000/chat/completions' \
        --header "Authorization: Bearer $LITELLM_MASTER_KEY" \
        --header 'Content-Type: application/json' \
        --header 'Editor-Version: CommandLine/1.0' \
        --data '{
        "model": "gemini-3-flash",
        "messages": [
            {
            "role": "user",
            "content": "what llm are you"
            }
        ]
        }'
}

test_claude_opus() {
    curl --location 'http://0.0.0.0:4000/chat/completions' \
        --header "Authorization: Bearer $LITELLM_MASTER_KEY" \
        --header 'Content-Type: application/json' \
        --header 'Editor-Version: CommandLine/1.0' \
        --data '{
        "model": "claude-opus-4",
        "messages": [
            {
            "role": "user",
            "content": "what llm are you"
            }
        ]
        }'
}

test_claude_haiku() {
    curl --location 'http://0.0.0.0:4000/chat/completions' \
        --header "Authorization: Bearer $LITELLM_MASTER_KEY" \
        --header 'Content-Type: application/json' \
        --header 'Editor-Version: CommandLine/1.0' \
        --data '{
        "model": "claude-haiku-4.5",
        "messages": [
            {
            "role": "user",
            "content": "what llm are you"
            }
        ]
        }'
}

test_claude_sonnet() {
    curl --location 'http://0.0.0.0:4000/chat/completions' \
        --header "Authorization: Bearer $LITELLM_MASTER_KEY" \
        --header 'Content-Type: application/json' \
        --header 'Editor-Version: CommandLine/1.0' \
        --data '{
        "model": "claude-sonnet-4",
        "messages": [
            {
            "role": "user",
            "content": "what llm are you"
            }
        ]
        }'
    
}

test_claude_sonnet45() {
    curl --location 'http://0.0.0.0:4000/chat/completions' \
        --header "Authorization: Bearer $LITELLM_MASTER_KEY" \
        --header 'Content-Type: application/json' \
        --header 'Editor-Version: CommandLine/1.0' \
        --data '{
        "model": "claude-sonnet-4.5",
        "messages": [
            {
            "role": "user",
            "content": "what llm are you"
            }
        ]
        }'
}

test_gpt4() {
    curl --location 'http://0.0.0.0:4000/chat/completions' \
        --header 'Content-Type: application/json' \
        --header 'Editor-Version: CommandLine/1.0' \
        --data '{
        "model": "gpt-4",
        "messages": [
            {
            "role": "user",
            "content": "what llm are you"
            }
        ]
        }'
}

test_models() {
    curl --location 'http://0.0.0.0:4000/v1/models' \
        --header 'Content-Type: application/json' \
        --header 'Editor-Version: CommandLine/1.0' 
}
